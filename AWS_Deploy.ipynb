{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL0BzT5_HNfv"
      },
      "source": [
        "# Deploy Yolo Model on AWS\n",
        "\n",
        "---\n",
        "\n",
        "- Reference:\n",
        "  - [HowTo: deploying YOLOv8 on AWS Lambda](https://www.trainyolo.com/blog/deploy-yolov8-on-aws-lambda)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idftbonCIzRp"
      },
      "source": [
        "## Optional - Google CodeLab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4pw4vsNI6Tu",
        "outputId": "dcf0ac57-e9a9-4aed-9e68-eaa3f83fcd6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# !pip install ultralytics\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY_QbiqyHgs0"
      },
      "source": [
        "## Converting YOLOv8 to ONNXz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "bfUqsug3HWfo",
        "outputId": "5624eb20-a86a-4225-cb45-2bca2fedf543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.1.9 ðŸš€ Python-3.11.5 torch-2.2.0+cpu CPU (12th Gen Intel Core(TM) i7-1255U)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'model\\car_plate\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (6.0 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 0.7s, saved as 'model\\car_plate\\best.onnx' (11.5 MB)\n",
            "\n",
            "Export complete (2.5s)\n",
            "Results saved to \u001b[1mC:\\Users\\simon\\iCloudDrive\\Documents\\Github\\VehiclePlateDetector\\model\\car_plate\u001b[0m\n",
            "Predict:         yolo predict task=detect model=model\\car_plate\\best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=model\\car_plate\\best.onnx imgsz=640 data=datasets/config.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'model\\\\car_plate\\\\best.onnx'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# load model\n",
        "MODEL_PATH = './model/car_plate/best.pt'\n",
        "model = YOLO(MODEL_PATH)\n",
        "\n",
        "# # export model\n",
        "model.export(format=\"onnx\", dynamic=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Local Jupyter Notebook\n",
        "  - ONNX file: `/deploy/model.onnx`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install AWS SAM CLI\n",
        "\n",
        "- rel:\n",
        "  - https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/install-sam-cli.html#install-sam-cli-instructions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Lambda function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from yolo_onnx.yolov8_onnx import YOLOv8\n",
        "import json\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "# Definec a global parameter for the Initialized YOLOv8 object detector\n",
        "# global parameter: remains in memory during the lifetime of the function; not be re-initialized for each function all\n",
        "yolo_detector = YOLOv8('model.onnx')\n",
        "\n",
        "\n",
        "def main(event, context):\n",
        "\n",
        "    # Get request body\n",
        "    body = json.loads(event['body'])\n",
        "\n",
        "    # get arguments\n",
        "    image = body['image']               # encoded image\n",
        "    size = body.get('size', 640)        # size\n",
        "    conf_thres = body.get('conf_thres', 0.3)        # confidence threshold\n",
        "    iou_thres = body.get('iou_thres', 0.5)          # IOU threshold\n",
        "\n",
        "    # decoded\n",
        "    img = Image.open(\n",
        "        BytesIO(\n",
        "            base64.b64decode(image.encode('ascii'))\n",
        "        ))\n",
        "\n",
        "    # predict\n",
        "    pred_yolo = yolo_detector(\n",
        "        img, size=size, conf_thres=conf_thres, iou_thres=iou_thres)\n",
        "\n",
        "    # return prediction\n",
        "    return {\n",
        "        \"statusCode\": 200,\n",
        "        \"body\": json.dumps({\n",
        "            \"detections\": pred_yolo\n",
        "        }),\n",
        "    }\n",
        "\n",
        "# return sample:\n",
        "# [\n",
        "#   {\"bbox\": [0, 264, 473, 1351], \"score\": 0.932, \"class_id\": 0},\n",
        "#   {\"bbox\": [1286, 199, 1918, 1353], \"score\": 0.93, \"class_id\": 0},\n",
        "#   {\"bbox\": [1047, 288, 1534, 1348], \"score\": 0.895, \"class_id\": 0},\n",
        "#   {\"bbox\": [494, 433, 943, 1357], \"score\": 0.895, \"class_id\": 0},\n",
        "#   {\"bbox\": [1021, 748, 1111, 901], \"score\": 0.679, \"class_id\": 41}\n",
        "# ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploying the Lambda function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
